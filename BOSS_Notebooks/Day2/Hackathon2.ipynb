{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inespetab/book_of_recipes/blob/main/BOSS_Notebooks/Day2/Hackathon2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24719321-e051-4dc4-9573-254ccaee4173",
      "metadata": {
        "id": "24719321-e051-4dc4-9573-254ccaee4173"
      },
      "source": [
        "### Hackathon 2: Optimisation of a Chemical Transformation with Bayesian Optimisation\n",
        "\n",
        "#### Hackathon Breif\n",
        "\n",
        "This hackathon involves the optimisation of reaction conditions for a Buchwald-Hartwig reaction with Bayesian Optimisation.\n",
        "\n",
        "![image.png](attachment:ab647aa1-021e-4dc3-a28c-9206c8c20a73.png)\n",
        "\n",
        "The reaction is performed at room temperature and with DMSO as a solvent. The pre-catalyst and base is varied.\n",
        "\n",
        "#### Input and Outputs\n",
        "The search space of the reaction condition includes 16 pre-catalysts and 6 bases. These are the same pre-catalysts and bases you have seen in Section B.\n",
        "\n",
        "![image.png](attachment:96f3300f-b4ed-47ab-9e9d-b807fa81b5de.png)\n",
        "\n",
        "The output is the yield of the reaction measured after a given time. Your goal is to obtain the set of reaction condition that corresponds to the highest yield. Notice that you are given a budget that is drastically smaller than the first hackathon - this is to emulate real experimentation (how many experiment can you do in parallel?). Details of the optimisation are given:\n",
        "\n",
        "```\n",
        "Optimisation Task : Minimisation.\n",
        "Constrains        : Budget of a maximum of 20 additional experiments (= iterations x batches) and a maximum of 4 batches per iteration. The BO optimisation will stop after a maximum runtime.\n",
        "Training points   : Allowed a maximum of 4 initial training points.\n",
        "```\n",
        "\n",
        "#### Running the Simulated Experiments\n",
        "The substrates of the reaction is not revealed. Your code will be tested against 3 unseen reactions (objective function). To develop your code, you can use the list of yields obtained in Section B. The yields are negative here as we are performing minimisation.\n",
        "\n",
        "```python\n",
        "reaction_yield = [-3.6, -3.9, -3.5, -3.3, -3.6, -3.0, -1.1, -0.7, -0.8, -0.6, -0.8, -1.2, -0.7, -1.5, -0.0, -0.0, -0.0, -0.5, -5.0, -0.0, -0.0, -1.6, -3.5, -6.6, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.5, -1.5, -0.0, -0.0, -0.0, -0.7, -0.0, -1.6, -0.0, -1.3, -2.2, -23.2, -0.0, -0.0, -0.0, -1.9, -4.0, -16.3, -4.0, -1.0, -0.0, -0.0, -0.0, -62.7, -0.4, -1.8, -1.7, -1.0, -0.0, -0.0, -0.1, -0.3, -0.3, -0.4, -0.4, -2.8, -1.1, -1.4, -2.6, -0.7, -1.4, -2.1, -10.9, -91.7, -100.0, -50.2, -27.8, -79.1, -0.0, -3.1, -0.0, -1.2, -1.8, -14.5, -0.5, -0.5, -0.0, -0.4, -0.6, -7.8, -3.1, -3.5, -3.2, -2.2, -3.0, -15.8]\n",
        "\n",
        "def experiment_yield(condition , X_searchspace):\n",
        "    return(reaction_yield[X_searchspace.index(condition)])\n",
        "```\n",
        "\n",
        "With this, the objective function is based on the index of your `X_searchspace` and reaction yield list being consistent. Your search space must be built according to the following order.\n",
        "\n",
        "```python\n",
        "precatalyst_descriptors = [['G3_BINAP',[...]],\n",
        "                           ['G3_DPPF',[...]],\n",
        "                           ['G2_XantPhos',[...]],\n",
        "                           ['G2_tertBu3P',[...]],\n",
        "                           ['G3_PPA',[...]],\n",
        "                           ['G3_Aphos',[...]],\n",
        "                           ['G3_Xphos',[...]],\n",
        "                           ['G2_RuPhos',[...]],\n",
        "                           ['G3_DTBPF',[...]],\n",
        "                           ['G3_J009',[...]],\n",
        "                           ['G3_MorDalPhos',[...]],\n",
        "                           ['G3_BrettPhos',[...]],\n",
        "                           ['G3_tertBuXPhos',[...]],\n",
        "                           ['G3_tertBuBrettPhos',[...]],\n",
        "                           ['G3_RockPhos',[...]],\n",
        "                           ['G3_AdBrettPhos',[...]]]\n",
        "\n",
        "base_descriptors = [['DBU', [...]],\n",
        "                    ['MTBD', [...]],\n",
        "                    ['BTMG', [...]],\n",
        "                    ['BEMP', [...]],\n",
        "                    ['BTTP', [...]],\n",
        "                    ['P2Et', [...]]]\n",
        "\n",
        "X_searchspace = []\n",
        "for precat in precatalyst_descriptors:\n",
        "    for base in base_descriptors:\n",
        "        X_searchspace += [precat[1]+base[1]]\n",
        "```\n",
        "\n",
        "#### Goals and Submission\n",
        "Using your knowledge of how Gaussian Processes and Bayesian Optimisation operate (mean function, convariance/kernal functions, initialisation points, acquisition functions, batch vs sequential etc.), your task is to develop two python classes: a GP class, a batch_BO class and chemical descriptors to obtain reaction conditions that corresponds to the highest yield under a tight budget.\n",
        "\n",
        "You are allowed to write your own BO class or make modifications to any of the previously seen BO classes. However, you must include the attributes `self.X` and `self.Y` corresponding to all of your evaluated inputs and outputs in your BO class as this will be used to retrive the information used for scoring.\n",
        "\n",
        "You must also include the input `objective_func` to your BO class and pass `experiment_yield` as the input when executing! To emulate real experiments, a `experimental_time` input is also included to add additional delays to the code (the isntructor will modified if needed, for example, when there is a large number of teams achieving the highest yield). You must include `experiment_time` in your BO class and pass `exp_time` as the input when executing.\n",
        "\n",
        "Please remove/comment your own test objective functions/experimental time delays when submitting!\n",
        "\n",
        "```python\n",
        "#submission should look something like the following\n",
        "class GP: #if you have any separate classes other than the BO class\n",
        "    def __init__(self, ...):\n",
        "        ...\n",
        "#BO class\n",
        "class BO:\n",
        "    def __init__(self, ...):\n",
        "        self.X = #training data which the evaluated data is to be appended\n",
        "        self.Y = #evaluated via the objective function using self.X\n",
        "\n",
        "# BO Execution Block\n",
        "X_training = [...]\n",
        "X_seachspace = [...]\n",
        "\n",
        "#Please remove/comment your objective functions and exp_time when submitting!\n",
        "#def obj_func(X):\n",
        "#\treturn (...)\n",
        "\n",
        "BO_m = BO(...,\n",
        "          objective_func = experiment_yield, #must include this exactly!\n",
        "          ...,\n",
        "          experiment_time = exp_time, #must include this exactly!\n",
        "          ...)\n",
        "```\n",
        "\n",
        "A template and example of a GP and BO class function can be seen below. Once completed, please upload your classes to the Stremlet submission page where your code will be tested. Again, the exact substrates for the reaction is not revealed but is based on a real Buchwald-Hartwig reaction dataset.\n",
        "\n",
        "The scoring is based on the highest total yield obtained! (see guidance for advanced teams).\n",
        "\n",
        "\n",
        "#### Guidance (Advanced):\n",
        "It is encouraged that you write your own GP/batch BO algorithm! You have a range of possibilities from implimenting more suitable kernels to using designer acquisition functions (given some knowledge of the underlying objective function - use your chemical intuition/knoweldge/literature to predict which combination works best and put these in your initial training data!).\n",
        "\n",
        "Your score will be further penalised by the total runtime. (ie. your final score will be `min(self.Y) + runtime`). Because the total number of experiments are limited, a large factor to the performance of BO algorithm is the quality of the chemical descriptors. A recommendation is to spend some time searching for good descriptors for the reagents and perform some decomposition (such as PCA) to limit the number of dimensions. rdkit is also among the available packages if you wish to do some molecular fingerprinting.\n",
        "\n",
        "#### Guidance (Intermediate):\n",
        "You are more than welcomed to write your own GP/BO algorithm! You can also use the template given below. You should have some familiarity with how the basic GP and BO class in the given template work from sections A and B.\n",
        "\n",
        "##### Some Starting Points to Help\n",
        "1. The reaction is given! You can look up which combination of reaction conditions work well from your own chemical intuition/literature data. You can use these are your initial training data.\n",
        "2. Similar to Section B, modify the code to include plots of how your BO functions are performing over each iteration. This will help you visualise and evaluate the usefulness of your modifications.\n",
        "3. A large factor to the performance of BO algorithm is the quality of the chemical descriptors. Could you find better/more meaningful descriptors to the reagents for the given transformations? Keep in mind that each additional descriptor is an additional dimension.\n",
        "4. Decide the initial training points (Random? Bias? Uniform distrubution?) and acquisition function (Greedy? Purely explorative? Lower confidence bounnd?) with the associated hyperparameters.\n",
        "\n",
        "Other points to consider: Better kernel function? How to include more descriptor information but keep the dimensions low?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "296c158a-1da5-4d48-a7c7-37e41a1194fd",
      "metadata": {
        "id": "296c158a-1da5-4d48-a7c7-37e41a1194fd"
      },
      "source": [
        "#### Package Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc9371b7-df7e-41a7-807b-c8be627e6694",
      "metadata": {
        "id": "dc9371b7-df7e-41a7-807b-c8be627e6694"
      },
      "outputs": [],
      "source": [
        "# if using google collab, run the following pip installs!\n",
        "!pip install sobol_seq\n",
        "!pip install plotly\n",
        "!pip install gpytorch\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "208a1a81-c0d8-45ca-8259-835cfb526a78",
      "metadata": {
        "id": "208a1a81-c0d8-45ca-8259-835cfb526a78"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.random as rnd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
        "import plotly.graph_objs as go\n",
        "from scipy.integrate import quad\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.optimize import minimize, differential_evolution, NonlinearConstraint\n",
        "from sklearn.decomposition import PCA\n",
        "import math\n",
        "import time\n",
        "import sobol_seq\n",
        "import torch\n",
        "import gpytorch\n",
        "import copy\n",
        "import rdkit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee929f0a-2482-48b2-81a5-64e1bde872b6",
      "metadata": {
        "id": "ee929f0a-2482-48b2-81a5-64e1bde872b6"
      },
      "source": [
        "#### GP class, BO class, BO Execution Template/Example"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ab659ac-7129-4251-b993-003c9574bedc",
      "metadata": {
        "id": "8ab659ac-7129-4251-b993-003c9574bedc"
      },
      "source": [
        "``` python\n",
        "class GP_model_meanzero:\n",
        "\n",
        "    def __init__(self, X, Y, kernel, hyperparams_multistart_loops):\n",
        "        self.X, self.Y, self.kernel = X, Y, kernel\n",
        "        self.number_of_point, self.nx_dimensions, self.ny_dimensions = X.shape[0], X.shape[1], Y.shape[1]\n",
        "        self.multistart_loops            = hyperparams_multistart_loops\n",
        "\n",
        "        self.X_mean, self.X_std     = np.mean(X, axis=0), np.std(X, axis=0)\n",
        "        self.Y_mean, self.Y_std     = np.mean(Y, axis=0), np.std(Y, axis=0)\n",
        "        self.X_norm, self.Y_norm    = (X-self.X_mean)/self.X_std, (Y-self.Y_mean)/self.Y_std\n",
        "\n",
        "        self.hyperparam_optimized , self.inverse_covariance_matrix_opt   = self.determine_hyperparameters()     \n",
        "        \n",
        "    def Cov_mat(self, kernel, X_norm, W, sf2):\n",
        "        if kernel == 'SquaredExponential':\n",
        "            xixj_euclidean_distance = cdist(X_norm, X_norm, 'seuclidean', V=W)**2\n",
        "            cov_matrix = sf2*np.exp(-0.5*xixj_euclidean_distance)\n",
        "            return (cov_matrix)\n",
        "        else:\n",
        "            print('ERROR no kernel with name ', kernel)\n",
        "\n",
        "\n",
        "    def negative_loglikelihood(self, hyper, X, Y):\n",
        "        n_point, nx_dim = self.number_of_point, self.nx_dimensions\n",
        "        kernel          = self.kernel\n",
        "         \n",
        "        W               = np.exp(2*hyper[:nx_dim])   # W <=> 1/lambda\n",
        "        sf2             = np.exp(2*hyper[nx_dim])    # variance of the signal\n",
        "        sn2             = np.exp(2*hyper[nx_dim+1])  # variance of noise\n",
        "\n",
        "        K       = self.Cov_mat(kernel, X, W, sf2)  \n",
        "        K       = K + (sn2 + 1e-8)*np.eye(n_point)\n",
        "        K       = (K + K.T)*0.5                   \n",
        "        L       = np.linalg.cholesky(K)            \n",
        "        logdetK = 2 * np.sum(np.log(np.diag(L)))   \n",
        "        invLY   = np.linalg.solve(L,Y)             \n",
        "        alpha   = np.linalg.solve(L.T,invLY)       \n",
        "        NLL     = np.dot(Y.T,alpha) + logdetK     \n",
        "        return (NLL)\n",
        "\n",
        "    \n",
        "    def determine_hyperparameters(self):\n",
        "        lower_bound = np.array([-4.]*(self.nx_dimensions+1) + [-8.])  # lengthscales + signal variance, noise variance\n",
        "        upper_bound = np.array([4.]*(self.nx_dimensions+1) + [ -2.])\n",
        "        bounds      = np.hstack((lower_bound.reshape(self.nx_dimensions+2,1), upper_bound.reshape(self.nx_dimensions+2,1)))\n",
        "\n",
        "        multi_startvec         = sobol_seq.i4_sobol_generate(self.nx_dimensions + 2, self.multistart_loops)\n",
        "        \n",
        "        temp_min_hyperparams   = [0.]*self.multistart_loops\n",
        "        temp_loglikelihood     = np.zeros((self.multistart_loops))\n",
        "        hyperparam_optimized   = np.zeros((self.nx_dimensions+2, self.ny_dimensions)) #for best solutions\n",
        "        inverse_covariance_matrix_opt = []\n",
        "        \n",
        "\n",
        "        for i in range(self.ny_dimensions):\n",
        "            for j in range(self.multistart_loops ):\n",
        "\n",
        "                hyperparams_initialisation   = lower_bound + (upper_bound-lower_bound)*multi_startvec[j,:] # mapping sobol unit cube to boudns\n",
        "               \n",
        "                result = minimize(self.negative_loglikelihood,\n",
        "                               hyperparams_initialisation,\n",
        "                               args=(self.X_norm, self.Y_norm[:,i]),\n",
        "                               method='SLSQP',\n",
        "                               options={'disp':False,'maxiter':10000},\n",
        "                               bounds=bounds,\n",
        "                               tol=1e-12)\n",
        "                \n",
        "                temp_min_hyperparams[j] = result.x\n",
        "                temp_loglikelihood[j]   = result.fun  \n",
        "\n",
        "\n",
        "            minimumloglikelihood_index    = np.argmin(temp_loglikelihood)\n",
        "            hyperparam_optimized[:,i]     = temp_min_hyperparams[minimumloglikelihood_index  ]\n",
        "    \n",
        "\n",
        "            lengthscale_opt         = np.exp(2.*hyperparam_optimized[:self.nx_dimensions,i])\n",
        "            signalvarience_opt      = np.exp(2.*hyperparam_optimized[self.nx_dimensions,i])\n",
        "            noise_opt               = np.exp(2.*hyperparam_optimized[self.nx_dimensions+1,i]) + 1e-8\n",
        "    \n",
        "            covarience_matrix_opt              = self.Cov_mat(self.kernel, self.X_norm, lengthscale_opt,signalvarience_opt) + noise_opt*np.eye(self.number_of_point)\n",
        "            self.covarience_matrix_opt         = covarience_matrix_opt\n",
        "            inverse_covariance_matrix_opt     += [np.linalg.solve(covarience_matrix_opt, np.eye(self.number_of_point))]\n",
        "            \n",
        "        return (hyperparam_optimized , inverse_covariance_matrix_opt)\n",
        "\n",
        "    def calc_cov_sample(self,xnorm,Xnorm,ell,sf2):\n",
        "        nx_dim = self.nx_dimensions\n",
        "        dist = cdist(Xnorm, xnorm.reshape(1,nx_dim), 'seuclidean', V=ell)**2\n",
        "        cov_matrix = sf2 * np.exp(-.5*dist)\n",
        "        return (cov_matrix )         \n",
        "\n",
        "\n",
        "    def GP_inference_np(self, x):\n",
        "        nx_dim                   = self.nx_dimensions\n",
        "        kernel, ny_dim           = self.kernel, self.ny_dimensions\n",
        "        hypopt, Cov_mat          = self.hyperparam_optimized, self.Cov_mat\n",
        "        stdX, stdY, meanX, meanY = self.X_std, self.Y_std, self.X_mean, self.Y_mean\n",
        "        calc_cov_sample          = self.calc_cov_sample\n",
        "        invKsample               = self.inverse_covariance_matrix_opt\n",
        "        Xsample, Ysample         = self.X_norm, self.Y_norm\n",
        "\n",
        "        xnorm = (x - meanX)/stdX\n",
        "        mean  = np.zeros(ny_dim)\n",
        "        var   = np.zeros(ny_dim)\n",
        "        \n",
        "        # ny_dim -> number of outputs\n",
        "        for i in range(ny_dim):\n",
        "            invK           = invKsample[i]\n",
        "            hyper          = hypopt[:,i]\n",
        "            ellopt, sf2opt = np.exp(2*hyper[:nx_dim]), np.exp(2*hyper[nx_dim])\n",
        "            k       = calc_cov_sample(xnorm,Xsample,ellopt,sf2opt)\n",
        "            mean[i] = np.matmul(np.matmul(k.T,invK),Ysample[:,i])\n",
        "            var[i]  = max(0, sf2opt - np.matmul(np.matmul(k.T,invK),k))\n",
        "\n",
        "        mean_sample = mean*stdY + meanY\n",
        "        var_sample  = var*stdY**2\n",
        "        \n",
        "        return (mean_sample, var_sample)\n",
        "\n",
        "\n",
        "\n",
        "class BO:\n",
        "    def __init__(self, X, kernel, X_searchspace, iterations,acquisition_function, objective_func,print_graph, acquisition_hyperparam, batch, experiment_time = 0):\n",
        "\n",
        "        self.X = np.array(X)\n",
        "        Fx_training = np.array([objective_func(x.tolist(),X_searchspace) for x in self.X])\n",
        "        self.Y = Fx_training.reshape(-1, 1)\n",
        "        \n",
        "\n",
        "        for i in range(iterations):\n",
        "            GP_m = GP_model_meanzero(self.X, self.Y, kernel, hyperparams_multistart_loops=3)\n",
        "\n",
        "            means = np.zeros(len(X_searchspace))\n",
        "            varience  = np.zeros(len(X_searchspace))\n",
        "            for idx, xx in enumerate(X_searchspace):\n",
        "                m, v = GP_m.GP_inference_np(xx)\n",
        "                means[idx] = m.item()\n",
        "                varience[idx]  = v.item()\n",
        "\n",
        "            \n",
        "            if acquisition_function == '':\n",
        "                # add acquisition function\n",
        "            else:\n",
        "                print('No acquisition function named', acquisition_function)\n",
        "\n",
        "            time.sleep(experiment_time)\n",
        "            new_Y = np.array([objective_func(x.tolist(),X_searchspace) for x in new_X]).reshape(-1, 1)\n",
        "            self.X = np.vstack([self.X, new_X])\n",
        "            self.Y = np.vstack([self.Y, new_Y])\n",
        "\n",
        "            if print_graph:\n",
        "                print(f\"Iteration {i} complete.\")\n",
        "\n",
        "\n",
        "#execution block\n",
        "X_training = [...]\n",
        "\n",
        "X_searchspace = []\n",
        "for precat in precatalyst_descriptors:\n",
        "    for base in base_descriptors:\n",
        "        X_searchspace += [precat[1]+base[1]]\n",
        "\n",
        "BO_m = BO(X = ,  \n",
        "         kernel =  ,\n",
        "         X_searchspace =  ,\n",
        "         iterations =  ,\n",
        "         acquisition_function =  ,\n",
        "         objective_func = experiment_yield, #must include this exactly!\n",
        "         print_graph =  ,\n",
        "         acquisition_hyperparam = ,\n",
        "         batch = ,\n",
        "         experiment_time = exp_time) #must include this exactly!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8dNzQV3lOHRf"
      },
      "id": "8dNzQV3lOHRf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GP_model_meanzero:\n",
        "\n",
        "    def __init__(self, X, Y, kernel, hyperparams_multistart_loops):\n",
        "        self.X, self.Y, self.kernel = X, Y, kernel\n",
        "        self.number_of_point, self.nx_dimensions, self.ny_dimensions = X.shape[0], X.shape[1], Y.shape[1]\n",
        "        self.multistart_loops            = hyperparams_multistart_loops\n",
        "\n",
        "        #Normalisation\n",
        "        self.X_mean, self.X_std     = np.mean(X, axis=0), np.std(X, axis=0)\n",
        "        self.Y_mean, self.Y_std     = np.mean(Y, axis=0), np.std(Y, axis=0)\n",
        "        self.X_norm, self.Y_norm    = (X-self.X_mean)/self.X_std, (Y-self.Y_mean)/self.Y_std\n",
        "\n",
        "        #Determine Kernel Hyperparameters\n",
        "        self.hyperparam_optimized , self.inverse_covariance_matrix_opt   = self.determine_hyperparameters()\n",
        "\n",
        "    def Cov_mat(self, kernel, X_norm, W, sf2):\n",
        "        if kernel == 'SquaredExponential':\n",
        "            xixj_euclidean_distance = cdist(X_norm, X_norm, 'seuclidean', V=W)**2\n",
        "            cov_matrix = sf2*np.exp(-0.5*xixj_euclidean_distance)\n",
        "            return (cov_matrix)\n",
        "        else:\n",
        "            print('ERROR no kernel with name ', kernel)\n",
        "\n",
        "\n",
        "    def negative_loglikelihood(self, hyper, X, Y):\n",
        "        # internal parameters\n",
        "        n_point, nx_dim = self.number_of_point, self.nx_dimensions\n",
        "        kernel          = self.kernel\n",
        "\n",
        "        W               = np.exp(2*hyper[:nx_dim])   # W <=> 1/lambda\n",
        "        sf2             = np.exp(2*hyper[nx_dim])    # variance of the signal\n",
        "        sn2             = np.exp(2*hyper[nx_dim+1])  # variance of noise\n",
        "\n",
        "        # obtaining negative logliklihood via Cholesky decomposition\n",
        "        K       = self.Cov_mat(kernel, X, W, sf2)\n",
        "        K       = K + (sn2 + 1e-8)*np.eye(n_point)\n",
        "        K       = (K + K.T)*0.5\n",
        "        L       = np.linalg.cholesky(K)\n",
        "        logdetK = 2 * np.sum(np.log(np.diag(L)))\n",
        "        invLY   = np.linalg.solve(L,Y)\n",
        "        alpha   = np.linalg.solve(L.T,invLY)\n",
        "        NLL     = np.dot(Y.T,alpha) + logdetK\n",
        "        return (NLL)\n",
        "\n",
        "\n",
        "    def determine_hyperparameters(self):\n",
        "        # setting up bounds for the log likelyhood minimsation\n",
        "        lower_bound = np.array([-4.]*(self.nx_dimensions+1) + [-8.])  # lengthscales + signal variance, noise variance\n",
        "        upper_bound = np.array([4.]*(self.nx_dimensions+1) + [ -2.])\n",
        "        bounds      = np.hstack((lower_bound.reshape(self.nx_dimensions+2,1), upper_bound.reshape(self.nx_dimensions+2,1)))\n",
        "\n",
        "        #gives number of input set of random starting guesses for each hyperparameter\n",
        "        multi_startvec         = sobol_seq.i4_sobol_generate(self.nx_dimensions + 2, self.multistart_loops)\n",
        "\n",
        "        #variables for storing information during loop\n",
        "        temp_min_hyperparams   = [0.]*self.multistart_loops\n",
        "        temp_loglikelihood     = np.zeros((self.multistart_loops))\n",
        "        hyperparam_optimized   = np.zeros((self.nx_dimensions+2, self.ny_dimensions)) #for best solutions\n",
        "        inverse_covariance_matrix_opt = []\n",
        "\n",
        "        #minimisation of hyperparameters\n",
        "        for i in range(self.ny_dimensions):\n",
        "            for j in range(self.multistart_loops ):\n",
        "                #initilising hyperparam guess\n",
        "                hyperparams_initialisation   = lower_bound + (upper_bound-lower_bound)*multi_startvec[j,:] # mapping sobol unit cube to boudns\n",
        "\n",
        "                result = minimize(self.negative_loglikelihood,\n",
        "                               hyperparams_initialisation,\n",
        "                               args=(self.X_norm, self.Y_norm[:,i]),\n",
        "                               method='SLSQP',\n",
        "                               options={'disp':False,'maxiter':10000},\n",
        "                               bounds=bounds,\n",
        "                               tol=1e-12)\n",
        "\n",
        "                temp_min_hyperparams[j] = result.x\n",
        "                temp_loglikelihood[j]   = result.fun\n",
        "\n",
        "            # choosing best solution from temporary lists\n",
        "            minimumloglikelihood_index    = np.argmin(temp_loglikelihood)\n",
        "            hyperparam_optimized[:,i]     = temp_min_hyperparams[minimumloglikelihood_index  ]\n",
        "\n",
        "            # exponential to recover value from log space\n",
        "            lengthscale_opt         = np.exp(2.*hyperparam_optimized[:self.nx_dimensions,i])\n",
        "            signalvarience_opt      = np.exp(2.*hyperparam_optimized[self.nx_dimensions,i])\n",
        "            noise_opt               = np.exp(2.*hyperparam_optimized[self.nx_dimensions+1,i]) + 1e-8\n",
        "\n",
        "            #obtain convarience matrix from optimised kernel hyper parameters\n",
        "            covarience_matrix_opt              = self.Cov_mat(self.kernel, self.X_norm, lengthscale_opt,signalvarience_opt) + noise_opt*np.eye(self.number_of_point)\n",
        "            self.covarience_matrix_opt         = covarience_matrix_opt\n",
        "            inverse_covariance_matrix_opt     += [np.linalg.solve(covarience_matrix_opt, np.eye(self.number_of_point))]\n",
        "\n",
        "        return (hyperparam_optimized , inverse_covariance_matrix_opt)\n",
        "\n",
        "    def calc_cov_sample(self,xnorm,Xnorm,ell,sf2):\n",
        "        # internal parameters\n",
        "        nx_dim = self.nx_dimensions\n",
        "\n",
        "        #covariance of sample\n",
        "        dist = cdist(Xnorm, xnorm.reshape(1,nx_dim), 'seuclidean', V=ell)**2\n",
        "        cov_matrix = sf2 * np.exp(-.5*dist)\n",
        "        return (cov_matrix )\n",
        "\n",
        "\n",
        "    def GP_inference_np(self, x):\n",
        "        nx_dim                   = self.nx_dimensions\n",
        "        kernel, ny_dim           = self.kernel, self.ny_dimensions\n",
        "        hypopt, Cov_mat          = self.hyperparam_optimized, self.Cov_mat\n",
        "        stdX, stdY, meanX, meanY = self.X_std, self.Y_std, self.X_mean, self.Y_mean\n",
        "        calc_cov_sample          = self.calc_cov_sample\n",
        "        invKsample               = self.inverse_covariance_matrix_opt\n",
        "        Xsample, Ysample         = self.X_norm, self.Y_norm\n",
        "\n",
        "        xnorm = (x - meanX)/stdX\n",
        "        mean  = np.zeros(ny_dim)\n",
        "        var   = np.zeros(ny_dim)\n",
        "\n",
        "        # ny_dim -> number of outputs\n",
        "        for i in range(ny_dim):\n",
        "            invK           = invKsample[i]\n",
        "            hyper          = hypopt[:,i]\n",
        "            ellopt, sf2opt = np.exp(2*hyper[:nx_dim]), np.exp(2*hyper[nx_dim])\n",
        "\n",
        "            # calculation of covaraince for each output\n",
        "            # although noise hyperparameter determiend, it is ignored here for better visualisation\n",
        "            k       = calc_cov_sample(xnorm,Xsample,ellopt,sf2opt)\n",
        "            mean[i] = np.matmul(np.matmul(k.T,invK),Ysample[:,i])\n",
        "            var[i]  = max(0, sf2opt - np.matmul(np.matmul(k.T,invK),k))\n",
        "\n",
        "        # un-normalisation (obtianing actual mean and variance)\n",
        "        mean_sample = mean*stdY + meanY\n",
        "        var_sample  = var*stdY**2\n",
        "\n",
        "        return (mean_sample, var_sample)\n"
      ],
      "metadata": {
        "id": "Gx1BzgN3OK1b"
      },
      "id": "Gx1BzgN3OK1b",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#option 1 class BO\n",
        "from scipy import stats as st\n",
        "class BO:\n",
        "    def __init__(self, X, kernel, X_searchspace, iterations,acquisition_function, objective_func,print_graph, acquisition_hyperparam, batch, experiment_time = 0):\n",
        "\n",
        "        self.X = np.array(X)\n",
        "        Fx_training = np.array([objective_func(x.tolist(),X_searchspace) for x in self.X])\n",
        "        self.Y = Fx_training.reshape(-1, 1)\n",
        "\n",
        "        # Define the acquisition functions\n",
        "        def lower_confidence_bound(mean, std, kappa):\n",
        "            return mean - kappa * std\n",
        "\n",
        "        def probability_of_improvement(mean, std, y_best):\n",
        "            with np.errstate(divide='warn'):\n",
        "                Z = (mean - y_best) / std\n",
        "                Z[std == 0] = 0  # Handle the case where std is zero\n",
        "                return st.norm.cdf(Z)\n",
        "\n",
        "        def expected_improvement(mean, std, y_best):\n",
        "            with np.errstate(divide='warn'):\n",
        "                Z = (mean - y_best) / std\n",
        "                Z[std == 0] = 0 # Handle the case where std is zero\n",
        "                ei = (mean - y_best) * st.norm.cdf(Z) + std * st.norm.pdf(Z)\n",
        "                ei[std == 0] = 0 # Set EI to 0 where std is 0\n",
        "                return ei\n",
        "\n",
        "\n",
        "        for i in range(iterations):\n",
        "            GP_m = GP_model_meanzero(self.X, self.Y, kernel, hyperparams_multistart_loops=3)\n",
        "\n",
        "            means = np.zeros(len(X_searchspace))\n",
        "            varience  = np.zeros(len(X_searchspace))\n",
        "            for idx, xx in enumerate(X_searchspace):\n",
        "                m, v = GP_m.GP_inference_np(xx)\n",
        "                means[idx] = m.item()\n",
        "                varience[idx]  = v.item()\n",
        "\n",
        "            std = np.sqrt(varience)\n",
        "            y_best = np.min(self.Y) # Assuming minimization\n",
        "\n",
        "            if acquisition_function == 'LCB':\n",
        "                 acquisition_values = lower_confidence_bound(means, std, acquisition_hyperparam) # acquisition_hyperparam would be kappa\n",
        "            elif acquisition_function == 'PI':\n",
        "                acquisition_values = probability_of_improvement(means, std, y_best)\n",
        "            elif acquisition_function == 'EI':\n",
        "                acquisition_values = expected_improvement(means, std, y_best)\n",
        "            else:\n",
        "                print('No acquisition function named', acquisition_function)\n",
        "                return # Exit if no valid acquisition function is chosen\n",
        "\n",
        "            # Select the next points to evaluate based on the acquisition function and batch size\n",
        "            # For minimization, we want to maximize the acquisition function for EI and PI,\n",
        "            # and minimize for LCB (or maximize the negative LCB)\n",
        "            if acquisition_function == 'LCB':\n",
        "                 sorted_indices = np.argsort(acquisition_values)[:batch] # Select the 'batch' smallest values\n",
        "            else: # PI and EI\n",
        "                 sorted_indices = np.argsort(acquisition_values)[-batch:] # Select the 'batch' largest values\n",
        "\n",
        "            new_X_indices = sorted_indices\n",
        "            new_X = np.array([X_searchspace[j] for j in new_X_indices])\n",
        "\n",
        "            time.sleep(experiment_time)\n",
        "            new_Y = np.array([objective_func(x.tolist(),X_searchspace) for x in new_X]).reshape(-1, 1)\n",
        "            self.X = np.vstack([self.X, new_X])\n",
        "            self.Y = np.vstack([self.Y, new_Y])\n",
        "\n",
        "            if print_graph:\n",
        "                print(f\"Iteration {i} complete. Best Y so far: {np.min(self.Y)}\")\n",
        "                # You could add plotting code here to visualize the results of the iteration\n",
        "\n",
        "\n",
        "precatalyst_descriptors = [['G3_BINAP',[622.20, 2]],\n",
        "                           ['G3_DPPF',[544.10, 2]],\n",
        "                           ['G2_XantPhos',[578.19, 2]],\n",
        "                           ['G2_tertBu3P',[202.19, 1]],\n",
        "                           ['G3_PPA',[292.12, 1]],\n",
        "                           ['G3_Aphos',[265.20, 1]],\n",
        "                           ['G3_Xphos',[476.36, 1]],\n",
        "                           ['G2_RuPhos',[466.30, 1]],\n",
        "                           ['G3_DTBPF',[474.23, 2]],\n",
        "                           ['G3_J009',[554.29, 2]],\n",
        "                           ['G3_MorDalPhos',[463.30, 1]],\n",
        "                           ['G3_BrettPhos',[536.38, 1]],\n",
        "                           ['G3_tertBuXPhos',[424.33, 1]],\n",
        "                           ['G3_tertBuBrettPhos',[484.35, 1]],\n",
        "                           ['G3_RockPhos',[468.35, 1]],\n",
        "                           ['G3_AdBrettPhos',[640.44, 1]]]\n",
        "\n",
        "base_descriptors = [['DBU', [24.3]],\n",
        "                    ['MTBD', [25.5]],\n",
        "                    ['BTMG', [23.6]],\n",
        "                    ['BEMP', [27.6]],\n",
        "                    ['BTTP', [28.4]],\n",
        "                    ['P2Et', [32.9]]]\n",
        "\n",
        "reaction_yield = [-3.6, -3.9, -3.5, -3.3, -3.6, -3.0, -1.1, -0.7, -0.8, -0.6, -0.8, -1.2, -0.7, -1.5, -0.0, -0.0, -0.0, -0.5, -5.0, -0.0, -0.0, -1.6, -3.5, -6.6, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.5, -1.5, -0.0, -0.0, -0.0, -0.7, -0.0, -1.6, -0.0, -1.3, -2.2, -23.2, -0.0, -0.0, -0.0, -1.9, -4.0, -16.3, -4.0, -1.0, -0.0, -0.0, -0.0, -62.7, -0.4, -1.8, -1.7, -1.0, -0.0, -0.0, -0.1, -0.3, -0.3, -0.4, -0.4, -2.8, -1.1, -1.4, -2.6, -0.7, -1.4, -2.1, -10.9, -91.7, -100.0, -50.2, -27.8, -79.1, -0.0, -3.1, -0.0, -1.2, -1.8, -14.5, -0.5, -0.5, -0.0, -0.4, -0.6, -7.8, -3.1, -3.5, -3.2, -2.2, -3.0, -15.8]\n",
        "\n",
        "def experiment_yield(condition , X_searchspace):\n",
        "    return(reaction_yield[X_searchspace.index(condition)])\n",
        "\n",
        "X_training = [[424.33, 1, 23.6],[468.35, 1, 24.3],[640.44, 1, 25.5], [622.20, 2, 28.4]] #optimum in start\n",
        "#X_training = [[544.1, 2, 32.9],[265.2, 1, 24.3],[640.44, 1, 25.5], [622.20, 2, 28.4]] #no good in start\n",
        "X_searchspace = []\n",
        "for precat in precatalyst_descriptors:\n",
        "    for base in base_descriptors:\n",
        "        X_searchspace += [precat[1]+base[1]]\n",
        "\n",
        "\n",
        "acquisition_function = 'LCB' #'LCB' or 'PI' or 'EI'\n",
        "acquisition_hyperparam = 1.96 # Set kappa if using LCB, otherwise can be None\n",
        "iterations = 4\n",
        "batch_size = 4\n",
        "experiment_time= 0\n",
        "\n",
        "\n",
        "# Experiment time delay (set to 0 for the hackathon submission unless instructed otherwise)\n",
        "exp_time = 0\n",
        "\n",
        "# Instantiate and run the BO\n",
        "BO_m = BO(X = X_training,\n",
        "          kernel = 'SquaredExponential', # Use the defined kernel\n",
        "          X_searchspace = X_searchspace,\n",
        "          iterations = iterations,\n",
        "          acquisition_function = acquisition_function,\n",
        "          objective_func = experiment_yield, #must include this exactly!\n",
        "          print_graph = True, # Set to True to see progress\n",
        "          acquisition_hyperparam = acquisition_hyperparam,\n",
        "          batch = batch_size,\n",
        "          experiment_time = exp_time) #must include this exactly!\n",
        "\n",
        "# After running, BO_m.X contains all evaluated inputs and BO_m.Y contains all evaluated outputs.\n",
        "print(\"\\nOptimization complete.\")\n",
        "print(f\"Total experiments performed: {len(BO_m.X)}\")\n",
        "print(f\"Best yield found: {np.min(BO_m.Y)}\")\n",
        "best_index = np.argmin(BO_m.Y)\n",
        "print(f\"Corresponding condition (descriptors): {BO_m.X[best_index]}\")\n",
        "\n",
        "# After your existing code...\n",
        "\n",
        "print(\"\\nOptimization complete.\")\n",
        "print(f\"Total experiments performed: {len(BO_m.X)}\")\n",
        "print(f\"Best yield found: {np.min(BO_m.Y)}\")\n",
        "best_index = np.argmin(BO_m.Y)\n",
        "best_condition = BO_m.X[best_index]\n",
        "print(f\"Corresponding condition (descriptors): {best_condition}\")\n",
        "\n",
        "print(\"\\nOptimization complete.\")\n",
        "print(f\"Total experiments performed: {len(BO_m.X)}\")\n",
        "print(f\"Best yield found: {np.min(BO_m.Y)}\")\n",
        "best_index = np.argmin(BO_m.Y)\n",
        "best_condition = BO_m.X[best_index]\n",
        "print(f\"Corresponding condition (descriptors): {best_condition}\")\n",
        "\n",
        "# Find the matching precatalyst and base names\n",
        "precat_name = None\n",
        "base_name = None\n",
        "\n",
        "# The first two elements are from precatalyst, the last from base\n",
        "precat_descriptor = best_condition[:2]\n",
        "base_descriptor = best_condition[2]\n",
        "\n",
        "# Search for precatalyst - convert both to lists for proper comparison\n",
        "for name, desc in precatalyst_descriptors:\n",
        "    if list(desc) == list(precat_descriptor):\n",
        "        precat_name = name\n",
        "        break\n",
        "\n",
        "# Search for base - compare just the pKa value (first element in base descriptor)\n",
        "for name, desc in base_descriptors:\n",
        "    if desc[0] == base_descriptor:\n",
        "        base_name = name\n",
        "        break\n",
        "\n",
        "print(f\"Corresponding precatalyst: {precat_name}\")\n",
        "print(f\"Corresponding base: {base_name}\")\n"
      ],
      "metadata": {
        "id": "V-z-XF_ZTdWl",
        "outputId": "80fdba23-f76a-4b72-af37-9b87cb96aa53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "V-z-XF_ZTdWl",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-474448734.py:126: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  mean[i] = np.matmul(np.matmul(k.T,invK),Ysample[:,i])\n",
            "/tmp/ipython-input-9-474448734.py:127: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  var[i]  = max(0, sf2opt - np.matmul(np.matmul(k.T,invK),k))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 complete. Best Y so far: -100.0\n",
            "Iteration 1 complete. Best Y so far: -100.0\n",
            "Iteration 2 complete. Best Y so far: -100.0\n",
            "Iteration 3 complete. Best Y so far: -100.0\n",
            "\n",
            "Optimization complete.\n",
            "Total experiments performed: 20\n",
            "Best yield found: -100.0\n",
            "Corresponding condition (descriptors): [424.33   1.    23.6 ]\n",
            "\n",
            "Optimization complete.\n",
            "Total experiments performed: 20\n",
            "Best yield found: -100.0\n",
            "Corresponding condition (descriptors): [424.33   1.    23.6 ]\n",
            "\n",
            "Optimization complete.\n",
            "Total experiments performed: 20\n",
            "Best yield found: -100.0\n",
            "Corresponding condition (descriptors): [424.33   1.    23.6 ]\n",
            "Corresponding precatalyst: G3_tertBuXPhos\n",
            "Corresponding base: BTMG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precatalyst_descriptors = [['G3_BINAP',[622.20, 2]],\n",
        "                           ['G3_DPPF',[544.10, 2]],\n",
        "                           ['G2_XantPhos',[578.19, 2]],\n",
        "                           ['G2_tertBu3P',[202.19, 1]],\n",
        "                           ['G3_PPA',[292.12, 1]],\n",
        "                           ['G3_Aphos',[265.20, 1]],\n",
        "                           ['G3_Xphos',[476.36, 1]],\n",
        "                           ['G2_RuPhos',[466.30, 1]],\n",
        "                           ['G3_DTBPF',[474.23, 2]],\n",
        "                           ['G3_J009',[554.29, 2]],\n",
        "                           ['G3_MorDalPhos',[463.30, 1]],\n",
        "                           ['G3_BrettPhos',[536.38, 1]],\n",
        "                           ['G3_tertBuXPhos',[424.33, 1]],\n",
        "                           ['G3_tertBuBrettPhos',[484.35, 1]],\n",
        "                           ['G3_RockPhos',[468.35, 1]],\n",
        "                           ['G3_AdBrettPhos',[640.44, 1]]]\n",
        "\n",
        "base_descriptors = [['DBU', [24.3]],\n",
        "                    ['MTBD', [25.5]],\n",
        "                    ['BTMG', [23.6]],\n",
        "                    ['BEMP', [27.6]],\n",
        "                    ['BTTP', [28.4]],\n",
        "                    ['P2Et', [32.9]]]\n",
        "\n",
        "reaction_yield = [-3.6, -3.9, -3.5, -3.3, -3.6, -3.0, -1.1, -0.7, -0.8, -0.6, -0.8, -1.2, -0.7, -1.5, -0.0, -0.0, -0.0, -0.5, -5.0, -0.0, -0.0, -1.6, -3.5, -6.6, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.5, -1.5, -0.0, -0.0, -0.0, -0.7, -0.0, -1.6, -0.0, -1.3, -2.2, -23.2, -0.0, -0.0, -0.0, -1.9, -4.0, -16.3, -4.0, -1.0, -0.0, -0.0, -0.0, -62.7, -0.4, -1.8, -1.7, -1.0, -0.0, -0.0, -0.1, -0.3, -0.3, -0.4, -0.4, -2.8, -1.1, -1.4, -2.6, -0.7, -1.4, -2.1, -10.9, -91.7, -100.0, -50.2, -27.8, -79.1, -0.0, -3.1, -0.0, -1.2, -1.8, -14.5, -0.5, -0.5, -0.0, -0.4, -0.6, -7.8, -3.1, -3.5, -3.2, -2.2, -3.0, -15.8]\n",
        "\n",
        "def experiment_yield(condition , X_searchspace):\n",
        "    return(reaction_yield[X_searchspace.index(condition)])\n",
        "\n",
        "X_training = [[544.1, 2, 32.9],[265.2, 1, 24.3],[640.44, 1, 25.5], [622.20, 2, 28.4]]\n",
        "X_searchspace = []\n",
        "for precat in precatalyst_descriptors:\n",
        "    for base in base_descriptors:\n",
        "        X_searchspace += [precat[1]+base[1]]\n",
        "\n",
        "BO_m = BO_multiD_batch_chemistry(X = X_training,\n",
        "   kernel = 'SquaredExponential',\n",
        "   X_searchspace = X_searchspace,\n",
        "   iterations = 15,\n",
        "   acquisition_function = 'ThompsonMarginal',\n",
        "   objective_func = experiment_yield,\n",
        "   print_graph = True,\n",
        "   acquisition_hyperparam=[3],\n",
        "   batch = 5,\n",
        "   experiment_time=0)"
      ],
      "metadata": {
        "id": "EFWh7yoSOK9-",
        "outputId": "99edca18-03c6-47eb-9383-bc15e50628b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "EFWh7yoSOK9-",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-474448734.py:126: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  mean[i] = np.matmul(np.matmul(k.T,invK),Ysample[:,i])\n",
            "/tmp/ipython-input-9-474448734.py:127: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  var[i]  = max(0, sf2opt - np.matmul(np.matmul(k.T,invK),k))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 complete.\n",
            "Iteration 1 complete.\n",
            "Iteration 2 complete.\n",
            "Iteration 3 complete.\n",
            "Iteration 4 complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-474448734.py:126: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  mean[i] = np.matmul(np.matmul(k.T,invK),Ysample[:,i])\n",
            "/tmp/ipython-input-9-474448734.py:127: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  var[i]  = max(0, sf2opt - np.matmul(np.matmul(k.T,invK),k))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 5 complete.\n",
            "Iteration 6 complete.\n",
            "Iteration 7 complete.\n",
            "Iteration 8 complete.\n",
            "Iteration 9 complete.\n",
            "Iteration 10 complete.\n",
            "Iteration 11 complete.\n",
            "Iteration 12 complete.\n",
            "Iteration 13 complete.\n",
            "Iteration 14 complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#option 2 class BO\n",
        "class BO_multiD_batch_chemistry:\n",
        "    def __init__(self, X, kernel, X_searchspace, iterations,acquisition_function, objective_func,print_graph, acquisition_hyperparam, batch, experiment_time):\n",
        "\n",
        "        self.X = np.array(X)\n",
        "        Fx_training = np.array([objective_func(x.tolist(),X_searchspace) for x in self.X])\n",
        "        self.Y = Fx_training.reshape(-1, 1)\n",
        "\n",
        "        self.minY = []\n",
        "        self.exploredY = []\n",
        "\n",
        "        for i in range(iterations):\n",
        "            GP_m = GP_model_meanzero(self.X, self.Y, kernel, hyperparams_multistart_loops=3)\n",
        "\n",
        "            means = np.zeros(len(X_searchspace))\n",
        "            varience  = np.zeros(len(X_searchspace))\n",
        "            for idx, xx in enumerate(X_searchspace):\n",
        "                m, v = GP_m.GP_inference_np(xx)\n",
        "                means[idx] = m.item()\n",
        "                varience[idx]  = v.item()\n",
        "\n",
        "\n",
        "            if acquisition_function == 'ThompsonMarginal':\n",
        "                new_X = []\n",
        "                for number in range(batch):\n",
        "                    ts_sample  = means + acquisition_hyperparam[0]*np.sqrt(varience)*np.random.randn(len(X_searchspace))\n",
        "                    new_X.append(X_searchspace[np.argmin(ts_sample)])\n",
        "                new_X = np.array(new_X)\n",
        "            else:\n",
        "                print('No acquisition function named', acquisition_function)\n",
        "\n",
        "            time.sleep(experiment_time)\n",
        "            new_Y = np.array([objective_func(x.tolist(),X_searchspace) for x in new_X]).reshape(-1, 1)\n",
        "            self.X = np.vstack([self.X, new_X])\n",
        "            self.Y = np.vstack([self.Y, new_Y])\n",
        "\n",
        "            self.minY     += [self.Y.min()]\n",
        "            self.exploredY += [new_Y.flatten().tolist()]\n",
        "\n",
        "            if print_graph:\n",
        "                print(f\"Iteration {i} complete.\")\n",
        "\n",
        "        plt.figure(figsize=(8,4), dpi=100)\n",
        "        plt.title('Minimum of Training Data set over Iterations')\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.plot(range(iterations), self.minY)\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(8,4), dpi=100)\n",
        "        plt.title('Evaluation Output over Iterations')\n",
        "        plt.xlabel('Iterations')\n",
        "        for i, vals in enumerate(self.exploredY):\n",
        "            plt.scatter([i]*batch, vals)\n",
        "        plt.show()\n",
        "\n",
        "precatalyst_descriptors = [['G3_BINAP',[622.20, 2]],\n",
        "                           ['G3_DPPF',[544.10, 2]],\n",
        "                           ['G2_XantPhos',[578.19, 2]],\n",
        "                           ['G2_tertBu3P',[202.19, 1]],\n",
        "                           ['G3_PPA',[292.12, 1]],\n",
        "                           ['G3_Aphos',[265.20, 1]],\n",
        "                           ['G3_Xphos',[476.36, 1]],\n",
        "                           ['G2_RuPhos',[466.30, 1]],\n",
        "                           ['G3_DTBPF',[474.23, 2]],\n",
        "                           ['G3_J009',[554.29, 2]],\n",
        "                           ['G3_MorDalPhos',[463.30, 1]],\n",
        "                           ['G3_BrettPhos',[536.38, 1]],\n",
        "                           ['G3_tertBuXPhos',[424.33, 1]],\n",
        "                           ['G3_tertBuBrettPhos',[484.35, 1]],\n",
        "                           ['G3_RockPhos',[468.35, 1]],\n",
        "                           ['G3_AdBrettPhos',[640.44, 1]]]\n",
        "\n",
        "base_descriptors = [['DBU', [24.3]],\n",
        "                    ['MTBD', [25.5]],\n",
        "                    ['BTMG', [23.6]],\n",
        "                    ['BEMP', [27.6]],\n",
        "                    ['BTTP', [28.4]],\n",
        "                    ['P2Et', [32.9]]]\n",
        "\n",
        "reaction_yield = [-3.6, -3.9, -3.5, -3.3, -3.6, -3.0, -1.1, -0.7, -0.8, -0.6, -0.8, -1.2, -0.7, -1.5, -0.0, -0.0, -0.0, -0.5, -5.0, -0.0, -0.0, -1.6, -3.5, -6.6, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.5, -1.5, -0.0, -0.0, -0.0, -0.7, -0.0, -1.6, -0.0, -1.3, -2.2, -23.2, -0.0, -0.0, -0.0, -1.9, -4.0, -16.3, -4.0, -1.0, -0.0, -0.0, -0.0, -62.7, -0.4, -1.8, -1.7, -1.0, -0.0, -0.0, -0.1, -0.3, -0.3, -0.4, -0.4, -2.8, -1.1, -1.4, -2.6, -0.7, -1.4, -2.1, -10.9, -91.7, -100.0, -50.2, -27.8, -79.1, -0.0, -3.1, -0.0, -1.2, -1.8, -14.5, -0.5, -0.5, -0.0, -0.4, -0.6, -7.8, -3.1, -3.5, -3.2, -2.2, -3.0, -15.8]\n",
        "\n",
        "def experiment_yield(condition , X_searchspace):\n",
        "    return(reaction_yield[X_searchspace.index(condition)])\n",
        "\n",
        "X_training = [[544.1, 2, 32.9],[265.2, 1, 24.3],[640.44, 1, 25.5], [622.20, 2, 28.4]]\n",
        "X_searchspace = []\n",
        "for precat in precatalyst_descriptors:\n",
        "    for base in base_descriptors:\n",
        "        X_searchspace += [precat[1]+base[1]]"
      ],
      "metadata": {
        "id": "OrG1X3FZTg3j"
      },
      "id": "OrG1X3FZTg3j",
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}